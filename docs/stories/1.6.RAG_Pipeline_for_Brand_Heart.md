# Story 1.6: RAG Pipeline for Brand Heart

## Status: Draft

## Story
**As a Conscious Creator,** I want the documents I upload to be intelligently processed and integrated into my Brand Heart, **so that** the AI can use them as a knowledge base to provide context-aware answers and generate highly personalized content.

## Acceptance Criteria
1.  When a document is uploaded to the `alma` storage bucket, its content is automatically processed and converted into vector embeddings.
2.  The generated embeddings are stored in a new `brand_documents` table, and each embedding is securely linked to the user who uploaded the file.
3.  When a user asks a question, the system performs a similarity search on their documents to find the most relevant context.
4.  The relevant context is then used to generate a final, context-aware answer.
5.  If a document is updated in the storage bucket, its corresponding embeddings in the database are automatically updated.
6.  If a document is deleted from the storage bucket, its corresponding embeddings are automatically deleted from the database.
7.  Users can only ever access or query their own documents.

## Tasks / Subtasks
- [ ] **Task 1: Create Database Schema (AC: 2, 7)**
    - [ ] Create the `brand_documents` table with a `vector` column and a `user_id` foreign key.
    - [ ] Enable Row Level Security and add policies to enforce data ownership.
- [ ] **Task 2: Create `process-document` Edge Function (AC: 1)**
    - [ ] Create a new Supabase Edge Function named `process-document`.
    - [ ] This function will be triggered on file upload.
    - [ ] It will read the file content, break it into chunks, and generate embeddings using the OpenAI API.
    - [ ] It will then store the chunks and embeddings in the `brand_documents` table.
- [ ] **Task 3: Create `update-document` Edge Function (AC: 5)**
    - [ ] Create a new Supabase Edge Function named `update-document`.
    - [ ] This function will be triggered on file update.
    - [ ] It will delete the old embeddings for the file and then re-run the processing logic from Task 2.
- [ ] **Task 4: Create `delete-document` Edge Function (AC: 6)**
    - [ ] Create a new Supabase Edge Function named `delete-document`.
    - [ ] This function will be triggered on file deletion.
    - [ ] It will delete all embeddings associated with the file from the `brand_documents` table.
- [ ] **Task 5: Create Storage Triggers (AC: 1, 5, 6)**
    - [ ] Create the necessary SQL triggers on the `alma` storage bucket to invoke the Edge Functions on `INSERT`, `UPDATE`, and `DELETE` events.
- [ ] **Task 6: Create `query-brand-heart` Edge Function (AC: 3, 4)**
    - [ ] Create a new Supabase Edge Function named `query-brand-heart`.
    - [ ] This function will take a user's question as input.
    - [ ] It will generate an embedding for the question and perform a similarity search on the `brand_documents` table.
    - [ ] It will return the most relevant document chunks.
- [ ] **Task 7: Implement Frontend Logic (AC: 3, 4)**
    - [ ] Create a new UI component for asking questions about the Brand Heart.
    - [ ] This component will call the `query-brand-heart` function to get the relevant context.
    - [ ] It will then call the OpenAI API with the question and the context to generate the final answer.
- [ ] **Task 8: Write Tests**
    - [ ] Write a test for the frontend component that mocks the `query-brand-heart` function.
    - [ ] Write tests for the Edge Functions using Deno's testing framework.

## Dev Notes
### Architecture
*   This feature will be implemented using a serverless, event-driven architecture. Supabase Storage triggers will be used to invoke Edge Functions, which will handle the RAG pipeline.
*   Data ownership is enforced at the database level using Row Level Security.
*   The `pgvector` extension must be enabled in the Supabase project.
